{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the en4 data so we can calculate the mixed layer depths\n",
    "\n",
    "files = glob('../../../data/en4/profiles/EN.4.2.2.f.profiles.c14*.nc')\n",
    "\n",
    "vars = ['DEPH_CORRECTED', 'JULD', 'LATITUDE', 'LONGITUDE', 'PSAL_CORRECTED', 'PSAL_CORRECTED_QC', 'POTM_CORRECTED', 'POTM_CORRECTED_QC', 'WMO_INST_TYPE']\n",
    "\n",
    "# load all the EN4 profiles\n",
    "\n",
    "ds = xr.open_mfdataset(files, combine='nested', concat_dim='N_PROF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a coordinate called N_PROF which is an array starting at 0\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "N_PROF = np.arange(ds.JULD.size)\n",
    "\n",
    "ds['N_PROF'] = (('N_PROF'), N_PROF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out all the data north of 40S\n",
    "\n",
    "idx = ds['LATITUDE'].values < -40\n",
    "\n",
    "ds = ds.isel(N_PROF=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into memory\n",
    "\n",
    "en4 = ds[vars].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the main dimention the date\n",
    "\n",
    "N_PROF = np.arange(en4.JULD.size)\n",
    "\n",
    "en4['N_PROF'] = (('N_PROF'), N_PROF)\n",
    "\n",
    "en4 = en4.sortby('JULD')\n",
    "\n",
    "en4 = en4.assign_coords(JULD=('N_PROF', en4.JULD.data))\n",
    "\n",
    "en4 = en4.swap_dims({'N_PROF':'JULD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many months there are\n",
    "\n",
    "month_counts = en4['JULD'].resample(JULD='M').count(dim='JULD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out all the data north of 90S (there is some weird data)\n",
    "\n",
    "idx = en4['LATITUDE'].values > -90\n",
    "\n",
    "en4 = en4.isel(JULD=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make longitude and latitude xarray coordinates\n",
    "\n",
    "en4=en4.assign_coords(LONGITUDE=('JULD', en4.LONGITUDE.data))\n",
    "en4=en4.assign_coords(LATITUDE=('JULD',  en4.LATITUDE.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data density\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,3))\n",
    "\n",
    "ax.bar(np.arange(month_counts['JULD'].size), month_counts, width=1, edgecolor='w')\n",
    "\n",
    "ax.xaxis.set_ticks(np.linspace(0, month_counts['JULD'].size, 12))\n",
    "\n",
    "ax.xaxis.set_ticks(np.arange(0, month_counts['JULD'].size, 12))\n",
    "\n",
    "ax.xaxis.set_ticklabels(np.arange(2004, 2024, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate density from the tempeature and salinity of the profiles\n",
    "\n",
    "import gsw\n",
    "\n",
    "density = gsw.rho(en4['PSAL_CORRECTED'], en4['POTM_CORRECTED'], en4['DEPH_CORRECTED']/1000)\n",
    "\n",
    "en4['DENSITY'] = (('JULD', 'N_LEVELS'), density.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertically grid the density data\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "z = np.arange(0, 1005, 5)\n",
    "\n",
    "density_gridded = np.ndarray([en4.JULD.size, z.size])\n",
    "\n",
    "for i in tqdm(range(en4.JULD.size)):\n",
    "\n",
    "    ds = en4.isel(JULD=i)\n",
    "\n",
    "    density_gridded[i] = griddata(ds.DEPH_CORRECTED, ds.DENSITY, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mixed layer depth\n",
    "\n",
    "from functions.calc_mld import calc_mld\n",
    "\n",
    "mld = calc_mld(density_gridded, z, den_lim=0.03, ref_dpt=10)\n",
    "\n",
    "en4['MLD'] = (('JULD'), mld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the mld\n",
    "\n",
    "en4.to_netcdf('../../../data/en4/en4_profiles_with_mixed_layer_depth.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estel font gridding function\n",
    "\n",
    "GS=3\n",
    "\n",
    "# grid 3d for 3d variables (2d + time)\n",
    "def grid_lat_3df(dsgpd_ln,gs=GS):\n",
    "    lat_min = (-90)\n",
    "    lat_max = (-40)\n",
    "    lat = np.arange(lat_min,lat_max+gs,gs)\n",
    "    lat_labels = np.arange(0,(1/gs)*(lat_max-lat_min),1)\n",
    "    # lat_labels = range(0,lat_max-lat_min,gs)\n",
    "    \n",
    "    return dsgpd_ln.groupby_bins('LATITUDE',lat,\n",
    "                       labels=lat_labels,\n",
    "                       restore_coord_dims=True).median(skipna=True) #,dim='profile_num')\n",
    "    \n",
    "def grid_lon_3d_f(dsgpd_t,gs=GS):\n",
    "    # define lon min and max resp\n",
    "    lon_min = -180\n",
    "    lon_max = 180\n",
    "    lon = np.arange(lon_min,lon_max+gs,gs)\n",
    "    lon_labels = np.arange(0,(1/gs)*(lon_max-lon_min),1)\n",
    "    # lon_labels = range(0,lon_max-lon_min,gs)\n",
    "\n",
    "    return dsgpd_t.groupby_bins('LONGITUDE',lon,\n",
    "                       labels=lon_labels,\n",
    "                       restore_coord_dims=True).apply(grid_lat_3df)\n",
    "    \n",
    "    \n",
    "def grid_var_3dflt(dsvar,clim='month',gs=GS):\n",
    "    \"\"\"for gridding spatially in 2D and time (3D).\"\"\"\n",
    "    if clim == 'season':\n",
    "        var = dsvar.groupby_bins(group='time.month',bins=range(0,15,3),labels=range(0,4)).apply(grid_lon_3d_f)\n",
    "    else:\n",
    "        var = dsvar.groupby('JULD.'+clim).apply(grid_lon_3d_f)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each monthly mld map with the location of the data embedded\n",
    "\n",
    "gs=3\n",
    "\n",
    "lat_min = (-90)\n",
    "lat_max = (-40)\n",
    "lat_grid = np.arange(lat_min,lat_max+gs,gs)[:-1]+1.5\n",
    "\n",
    "lon_min = -180\n",
    "lon_max = 180\n",
    "lon_grid = np.arange(lon_min,lon_max+gs,gs)[:-1]+1.5\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "for year in range(2004,2024):\n",
    "\n",
    "    # Define the start and end dates for the year you want to select\n",
    "    start_date = str(year) + '-01-01'  # Replace YYYY with the year you're interested in\n",
    "    end_date = str(year) + '-12-31'\n",
    "    \n",
    "    ds = en4.sel(JULD=slice(start_date, end_date))\n",
    "\n",
    "    mld_month = grid_var_3dflt(ds['MLD'])\n",
    "\n",
    "    # Assuming 'en4' is your Dataset and 'JULD' is the datetime variable\n",
    "    grouped_by_month = ds.groupby(ds.JULD.dt.month)    \n",
    "    \n",
    "    for month, group in grouped_by_month:\n",
    "\n",
    "        mld_grid = mld_month.sel(month=month)\n",
    "        \n",
    "        mld = group.MLD\n",
    "        lon = group.LONGITUDE[mld>0]\n",
    "        lat = group.LATITUDE[mld>0]  \n",
    "        mld = mld[mld>0]\n",
    "    \n",
    "        fig = plt.figure(figsize=[3.5, 4.5])\n",
    "        ax = fig.add_subplot(1, 1, 1, projection=ccrs.SouthPolarStereo())\n",
    "        ax = southern_ocean_map(ax)\n",
    "\n",
    "        ax.pcolormesh(lon_grid, lat_grid, mld_grid.T, cmap=cmo.dense, vmin=0, vmax=200, transform=ccrs.PlateCarree())\n",
    "        ax.scatter(lon, lat, s=0.1, c='k', transform=ccrs.PlateCarree())\n",
    "\n",
    "        \n",
    "        if month < 10:\n",
    "            ax.set_title(str(year) + '-0' + str(month), fontsize=12, pad=7.5)\n",
    "            plt.savefig('/Users/xduplm/Google Drive/My Drive/projects/2023_duplessis_storms_fluxes/figs/en4_month_maps/' + 'map_en4_' + str(year) + '_0' + str(month) + '.png', dpi=300)\n",
    "            plt.close()\n",
    "        \n",
    "        else:\n",
    "            ax.set_title(str(year) + '-' + str(month), fontsize=12, pad=7.5)\n",
    "            plt.savefig('/Users/xduplm/Google Drive/My Drive/projects/2023_duplessis_storms_fluxes/figs/en4_month_maps/' + 'map_en4_' + str(year) + '_' + str(month) + '.png', dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new monthly dataset of MLDs\n",
    "\n",
    "for year in tqdm(range(2004,2024)):\n",
    "\n",
    "    # Define the start and end dates for the year you want to select\n",
    "    start_date = str(year) + '-01-01'  # Replace YYYY with the year you're interested in\n",
    "    end_date = str(year) + '-12-31'\n",
    "    \n",
    "    ds = en4.sel(JULD=slice(start_date, end_date))\n",
    "\n",
    "    mld_month = grid_var_3dflt(ds['MLD'])\n",
    "\n",
    "    if year==2004:\n",
    "\n",
    "        ds_mld = np.array(mld_month)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ds_mld = np.append(ds_mld, mld_month, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('2004-01-01', '2024-01-01', freq='M')\n",
    "\n",
    "# Create the Dataset\n",
    "mld_month = xr.Dataset({\n",
    "    'MLD': xr.DataArray(\n",
    "        data=ds_mld,\n",
    "        dims=['time', 'lon', 'lat'],\n",
    "        coords={'time': dates, 'lon': lon_grid, 'lat': lat_grid},\n",
    "        attrs={'long_name': 'Mixed Layer Depth', 'units': 'm'}\n",
    "    )\n",
    "})\n",
    "\n",
    "mld_month.to_netcdf('/Users/xduplm/Google Drive/My Drive/data/duplessis-storms-paper/en4_monthly_mixed_layer_depth_median.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
